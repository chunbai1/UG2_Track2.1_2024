{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from csv import reader\n",
    "\n",
    "class TextDataset(Dataset): \n",
    "    def __init__(self, label_file, img_path, transform = None): \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.labels = []\n",
    "        with open(label_file, 'r') as read_obj:\n",
    "            csv_reader = reader(read_obj)\n",
    "            for i, row in enumerate(csv_reader):\n",
    "                if i == 0: \n",
    "                    self.phase = row[0]\n",
    "                    img_num = int(row[1])\n",
    "                    self.len = int(row[2])\n",
    "                    \n",
    "                else: \n",
    "                    self.labels.append(row)\n",
    "                    \n",
    "        self.imgs = []\n",
    "        for i in range(img_num): \n",
    "            self.imgs.append(Image.open(os.path.join(img_path,'scene_{}_out.png'.format(i+1))).convert('L'))\n",
    "            \n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        label = self.labels[idx]\n",
    "        coordinates = [int(i) for i in label[2:]]\n",
    "        patch = self.imgs[int(label[0])-1].crop(coordinates)\n",
    "        patch = self.transform(patch)\n",
    "        \n",
    "        return (patch, label[1])\n",
    "    \n",
    "    \n",
    "class transform_CRNN():\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = img.resize(self.size, self.interpolation)\n",
    "        img = self.toTensor(img)\n",
    "        img.sub_(0.5).div_(0.5)\n",
    "        return img  \n",
    "    \n",
    "    \n",
    "class transform_DAN():\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = img.resize(self.size, self.interpolation)\n",
    "        img = self.toTensor(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    \n",
    "class transform_ASTER(): \n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = img.resize(self.size, self.interpolation)\n",
    "        img = self.toTensor(img)\n",
    "        img.sub_(0.5).div_(0.5)\n",
    "        img = img.repeat(3,1,1)\n",
    "        return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dataset\n",
    "import argparse\n",
    "from csv import reader\n",
    "\n",
    "from CRNN.utils import strLabelConverter\n",
    "from CRNN.crnn import CRNN\n",
    "\n",
    "from ASTER.models.model_builder import ModelBuilder\n",
    "from ASTER.utils import DataInfo, get_str_list\n",
    "\n",
    "from DAN.utils import load_network, flatten_label\n",
    "\n",
    "\n",
    "def arg_parse(): \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('image_path', help = 'path to the images for evaluation')\n",
    "    parser.add_argument('label_file', help = 'csv file containing the label info')\n",
    "    parser.add_argument('--method', default = 'all', help = 'method for evaluation: [CRNN, DAN, ASTER, all]')\n",
    "    parser.add_argument('--batch_size', type=int, default = 64)\n",
    "    parser.add_argument('--cpu', action = 'store_true')\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def evaluate_CRNN(args, result_file): \n",
    "    use_gpu = ~args.cpu\n",
    "    \n",
    "    print('Start evaluating with CRNN')\n",
    "    transforms = dataset.transform_CRNN((100,32))\n",
    "    textset = dataset.TextDataset(args.label_file,args.image_path,transform = transforms)\n",
    "    data_loader = torch.utils.data.DataLoader(textset, batch_size=args.batch_size)\n",
    "    \n",
    "    converter = strLabelConverter(alphabet = '0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "    \n",
    "    model = CRNN(32, 1, 37, 256)\n",
    "    model.load_state_dict(torch.load('./CRNN/crnn.pth'))\n",
    "    \n",
    "    if torch.cuda.is_available() and use_gpu: \n",
    "        model = model.cuda()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    if textset.phase == 'dry run': \n",
    "        log_file = open('log_CRNN.txt', 'w')\n",
    "    \n",
    "    for data in data_loader:      \n",
    "        if textset.phase == 'dry run': \n",
    "            images, labels = data\n",
    "        else: \n",
    "            images = data\n",
    "        \n",
    "        if torch.cuda.is_available() and use_gpu: \n",
    "            images = images.cuda()\n",
    "\n",
    "        preds = model(images)\n",
    "        preds_size = torch.IntTensor([preds.size(0)] * images.shape[0])\n",
    "\n",
    "        _, preds = preds.max(2)\n",
    "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "        pred_strs = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "        \n",
    "        for pred_str in pred_strs: \n",
    "            result_file.write(pred_str+'\\n')\n",
    "            \n",
    "        if textset.phase == 'dry run':\n",
    "            for pred_str, label in zip(pred_strs,labels): \n",
    "                if pred_str == label: \n",
    "                    correct += 1\n",
    "                    log_file.write('label: {}, predicted: {}, correct! \\n'.format(label,pred_str))\n",
    "                else: \n",
    "                    log_file.write('label: {}, predicted: {}, incorrect! \\n'.format(label,pred_str))\n",
    "                    \n",
    "    if textset.phase == 'dry run':                \n",
    "        print('Finished evaluating with CRNN, result: {}/{}'.format(correct,textset.len))\n",
    "        log_file.write('Result: {}/{}\\n'.format(correct,textset.len))\n",
    "        log_file.close()\n",
    "    else: \n",
    "        print('Finished evaluating with CRNN')\n",
    "    \n",
    "    \n",
    "def evaluate_DAN(args, result_file): \n",
    "    use_gpu = ~args.cpu\n",
    "    \n",
    "    print('Start evaluating with DAN')\n",
    "    transforms = dataset.transform_DAN((128,32))\n",
    "    textset = dataset.TextDataset(args.label_file,args.image_path,transform = transforms)\n",
    "    data_loader = torch.utils.data.DataLoader(textset, batch_size=args.batch_size)\n",
    "    \n",
    "    models, encdec = load_network()\n",
    "    for model in models: \n",
    "        model.eval()\n",
    "        if torch.cuda.is_available() and use_gpu: \n",
    "            model = model.cuda()\n",
    "    \n",
    "    label = ['0123456789abcdefghijklmnopqrstuvwxyz']\n",
    "    target = encdec.encode(label)\n",
    "    label_flatten, length = flatten_label(target)\n",
    "    length = length.unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available() and use_gpu: \n",
    "        target = target.cuda()\n",
    "        label_flatten = label_flatten.cuda()\n",
    "    \n",
    "    correct = 0\n",
    "    if textset.phase == 'dry run': \n",
    "        log_file = open('log_DAN.txt', 'w')\n",
    "    \n",
    "    for data in data_loader:      \n",
    "        if textset.phase == 'dry run': \n",
    "            images, labels = data\n",
    "        else: \n",
    "            images = data\n",
    "            \n",
    "        if torch.cuda.is_available() and use_gpu: \n",
    "            images = images.cuda()\n",
    "\n",
    "        features = models[0](images)\n",
    "        A = models[1](features)\n",
    "        output, out_length = models[2](features[-1], A, target, length, True)\n",
    "\n",
    "        pred_strs = encdec.decode(output,out_length)[0]\n",
    "\n",
    "        for pred_str in pred_strs: \n",
    "            result_file.write(pred_str+'\\n')\n",
    "            \n",
    "        if textset.phase == 'dry run':\n",
    "            for pred_str, label in zip(pred_strs,labels): \n",
    "                if pred_str == label: \n",
    "                    correct += 1\n",
    "                    log_file.write('label: {}, predicted: {}, correct! \\n'.format(label,pred_str))\n",
    "                else: \n",
    "                    log_file.write('label: {}, predicted: {}, incorrect! \\n'.format(label,pred_str))\n",
    "                    \n",
    "    if textset.phase == 'dry run':                \n",
    "        print('Finished evaluating with DAN, result: {}/{}'.format(correct,textset.len))\n",
    "        log_file.write('Result: {}/{}\\n'.format(correct,textset.len))\n",
    "        log_file.close()\n",
    "    else: \n",
    "        print('Finished evaluating with DAN')\n",
    "    \n",
    "    \n",
    "def evaluate_ASTER(args, result_file): \n",
    "    use_gpu = ~args.cpu\n",
    "    \n",
    "    if torch.cuda.is_available() and use_gpu: \n",
    "        print('using_GPU')\n",
    "        \n",
    "    print('Start evaluating with ASTER')\n",
    "    transforms = dataset.transform_ASTER((100,32))\n",
    "    textset = dataset.TextDataset(args.label_file,args.image_path,transform = transforms)\n",
    "    data_loader = torch.utils.data.DataLoader(textset, batch_size=args.batch_size)\n",
    "    \n",
    "    dataset_info = DataInfo('ALLCASES_SYMBOLS')\n",
    "    model = ModelBuilder(arch='ResNet_ASTER', rec_num_classes=dataset_info.rec_num_classes,\n",
    "                           sDim=512, attDim=512, max_len_labels=100,\n",
    "                           eos=dataset_info.char2id[dataset_info.EOS], STN_ON=True)\n",
    "    model.load_state_dict(torch.load('./ASTER/demo.pth.tar')['state_dict'])\n",
    "    \n",
    "    if torch.cuda.is_available() and use_gpu: \n",
    "        device = torch.device('cuda')\n",
    "        model = model.to(device)\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    model.eval()\n",
    "            \n",
    "    correct = 0\n",
    "    if textset.phase == 'dry run': \n",
    "        log_file = open('log_ASTER.txt', 'w')\n",
    "    \n",
    "    for data in data_loader: \n",
    "        if textset.phase == 'dry run': \n",
    "            images, labels = data\n",
    "        else: \n",
    "            images = data\n",
    "        \n",
    "        if torch.cuda.is_available() and use_gpu: \n",
    "            with torch.no_grad(): \n",
    "                images = images.to(device)\n",
    "        \n",
    "        input_dict = {}\n",
    "        input_dict['images'] = images\n",
    "        rec_targets = torch.IntTensor(images.shape[0], 100).fill_(1)\n",
    "        rec_targets[:,100-1] = dataset_info.char2id[dataset_info.EOS]\n",
    "        rec_targets = rec_targets.cuda()\n",
    "        input_dict['rec_targets'] = rec_targets\n",
    "        input_dict['rec_lengths'] = [100]\n",
    "        print(model.get_device())\n",
    "        output_dict = model(input_dict)\n",
    "        \n",
    "        pred_strs, _ = get_str_list(output_dict['output']['pred_rec'], input_dict['rec_targets'], dataset=dataset_info)\n",
    "        \n",
    "        for pred_str in pred_strs: \n",
    "            result_file.write(pred_str+'\\n')\n",
    "            \n",
    "        if textset.phase == 'dry run':\n",
    "            for pred_str, label in zip(pred_strs,labels): \n",
    "                if pred_str == label: \n",
    "                    correct += 1\n",
    "                    log_file.write('label: {}, predicted: {}, correct! \\n'.format(label,pred_str))\n",
    "                else: \n",
    "                    log_file.write('label: {}, predicted: {}, incorrect! \\n'.format(label,pred_str))\n",
    "                    \n",
    "    if textset.phase == 'dry run':                \n",
    "        print('Finished evaluating with ASTER, result: {}/{}'.format(correct,textset.len))\n",
    "        log_file.write('Result: {}/{}\\n'.format(correct,textset.len))\n",
    "        log_file.close()\n",
    "    else: \n",
    "        print('Finished evaluating with ASTER')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__': \n",
    "    args = arg_parse()\n",
    "    \n",
    "    result_file = open('./result.txt','w')\n",
    "    \n",
    "    if args.method == 'CRNN': \n",
    "        evaluate_CRNN(args, result_file)\n",
    "    elif args.method == 'DAN': \n",
    "        evaluate_DAN(args, result_file)\n",
    "    elif args.method == 'ASTER': \n",
    "        evaluate_ASTER(args, result_file)\n",
    "    elif args.method == 'all': \n",
    "        evaluate_CRNN(args, result_file)\n",
    "        evaluate_DAN(args, result_file)\n",
    "        evaluate_ASTER(args, result_file)\n",
    "        \n",
    "    result_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg_parse1():\n",
    "    image_path = './images'\n",
    "    label_file = 'labels_dry_run.csv'\n",
    "    method = 'ASTER'\n",
    "    batch_size = 1\n",
    "    cpu = False   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using_GPU\n",
      "Start evaluating with ASTER\n",
      "1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'get_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_244504/3067498536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevaluate_DAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ASTER'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mevaluate_ASTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mevaluate_CRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_244504/2084284648.py\u001b[0m in \u001b[0;36mevaluate_ASTER\u001b[0;34m(args, result_file)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec_targets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec_lengths'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cent7/2020.11-py38/pytorch1.10/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'get_device'"
     ]
    }
   ],
   "source": [
    "args = arg_parse1()\n",
    "\n",
    "result_file = open('./result.txt','w')\n",
    "\n",
    "if args.method == 'CRNN': \n",
    "    evaluate_CRNN(args, result_file)\n",
    "elif args.method == 'DAN': \n",
    "    evaluate_DAN(args, result_file)\n",
    "elif args.method == 'ASTER': \n",
    "    evaluate_ASTER(args, result_file)\n",
    "elif args.method == 'all': \n",
    "    evaluate_CRNN(args, result_file)\n",
    "    evaluate_DAN(args, result_file)\n",
    "    evaluate_ASTER(args, result_file)\n",
    "\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.10",
   "language": "python",
   "name": "pytorch1.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
